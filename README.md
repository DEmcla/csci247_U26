# CSCI 247: Plausible Lies

**Evaluating AI and the Tools That Shape What We Know**

A course teaching students to critically evaluate AI and digital tools—not build them. No prerequisites, no coding required. Open to all majors.

---

## What This Course Is

Students graduate without knowing how to evaluate the tools they'll use for the rest of their careers. This course teaches a transferable framework for evaluating any technology—current or future—by asking the right questions:

- **Function**: Does it do what it claims?
- **Data**: What's it trained on? What does it collect?
- **Failures**: Where does it break? How badly?
- **Access**: Who can use this? Who's excluded?
- **Terms**: What am I agreeing to?
- **Broader Impact**: What happens at scale? Who benefits? Who's harmed?

The framework predates AI and will outlast current tools. AI is just our test case.

---

## Course Versions

### In-Person (14 weeks)
Full semester course with twice-weekly meetings. Includes hands-on activities, presentations, and peer discussions.

**Files:**
- `in-person/CSCI247_Plausible_Lies_Student_Packet.docx` — Student-facing syllabus, assignments, framework
- `in-person/CSCI247_Plausible_Lies_Instructor_Packet.docx` — Week-by-week lesson plans, activities, facilitation notes

### Online (6 weeks, Summer)
Accelerated asynchronous online version for summer sessions. Fully redesigned for online delivery.

**Files:**
- `online/CSCI247_Plausible_Lies_ONLINE_Student_Packet.docx` — Technical requirements, weekly structure, assignments
- `online/CSCI247_Plausible_Lies_ONLINE_Instructor_Packet.docx` — Video production guide, discussion facilitation, time management

### Supporting Documents
- `docs/CSCI247_Plausible_Lies_Curriculum_Brief.docx` — One-page overview for curriculum committees

---

## Course Parameters

| Parameter | In-Person | Online |
|-----------|-----------|--------|
| Duration | 14 weeks | 6 weeks |
| Meetings | 2x/week, 75 min | Asynchronous |
| Enrollment Cap | 25 | 20 (10 first run) |
| Prerequisites | None | None |
| Coding Required | No | No |

---

## Assessments

| Assessment | Weight | Description |
|------------|--------|-------------|
| AI Tool Audit | 25% | Evaluate an unfamiliar AI tool using the framework |
| Personal Security Audit | 25% | Audit digital footprint; implement real changes |
| Participation/Weekly Work | 20% | In-class activities or online discussions |
| Tool Adaptability Exercise | 30% | Apply framework to novel tool under time pressure |

---

## Learning Outcomes

Students completing this course will be able to:

1. Systematically evaluate any technology using a transferable framework
2. Identify how computational systems fail and assess severity in context
3. Make informed decisions about privacy, security, and data trade-offs
4. Create professional documents and organize data effectively
5. Navigate professional and academic integrity questions involving AI
6. Adapt to new tools independently, without waiting for instruction

---

## Key Design Principles

**Framework, not tools.** Specific tools are examples, not content. The evaluation framework applies to any technology.

**Judgment, not compliance.** Assessments reward thoughtful analysis of trade-offs, not correct answers.

**Historical context.** AI is just the current instance of a long-standing problem: computational systems that shape meaning, authority, and trust—often invisibly.

**Durability by design.** Examples refresh annually; principles persist.

---

## Practical Skills Included

While evaluation is the focus, students also build:

- Word: Styles, track changes, accessibility, templates
- Excel: Data organization, formulas, failure modes (optional in online version)
- Security: Password managers, MFA, privacy settings
- Collaboration: Async communication, file management, version control

---

## For Instructors

The instructor packets include:

- Detailed week-by-week lesson plans
- Minute-by-minute class timings (in-person)
- Discussion facilitation guidance (online)
- Materials checklists
- Sample activities and scenarios
- Grading rubrics
- Time management recommendations
- First-day scripts for addressing the "CSCI" barrier

---

## Relationship to "Calling Bullshit"

This course complements Bergstrom & West's "Calling Bullshit" (statistical and media literacy) by addressing a different mechanism: systems that generate plausible content without understanding. Different mechanism, same epistemological problem.

---

## License

[Add your preferred license]

---

## Contributing

[Add contribution guidelines if desired]

---

## Contact

[Add contact information]
