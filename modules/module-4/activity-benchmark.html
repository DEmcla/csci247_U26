<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Activity: Benchmark BS Detection</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; padding: 20px; color: #333; }
        h1 { color: #1a5276; border-bottom: 3px solid #1a5276; padding-bottom: 10px; }
        h2 { color: #2874a6; margin-top: 25px; }
        .intro { background-color: #f8f9fa; border-left: 4px solid #2874a6; padding: 15px; margin: 15px 0; }
        .step { background-color: #e8f4f8; border: 1px solid #5bc0de; border-radius: 5px; padding: 15px; margin: 15px 0; }
        .step h3 { margin-top: 0; color: #2874a6; }
        .answer-space { background-color: #fff; border: 2px dashed #ccc; padding: 15px; margin: 10px 0; min-height: 80px; }
        .note { background-color: #fff9e6; border-left: 4px solid #f0ad4e; padding: 15px; margin: 15px 0; }
        .submit { background-color: #d4edda; border-left: 4px solid #28a745; padding: 15px; margin: 15px 0; }
    </style>
</head>
<body>

<h1>Benchmark BS Detection</h1>

<div class="intro">
    <p><strong>Purpose:</strong> Critically evaluate published AI benchmark claims. Learn to identify potential issues with how performance is measured and reported.</p>
    <p><strong>Time:</strong> 45-60 minutes</p>
</div>

<h2>The Exercise</h2>

<div class="step">
    <h3>Step 1: Find a Benchmark Claim</h3>
    <p>Search for an AI tool or model making performance claims. Look for statements like:</p>
    <ul>
        <li>"Achieves 95% accuracy on [benchmark]"</li>
        <li>"Outperforms GPT-4 on [task]"</li>
        <li>"#1 on [leaderboard]"</li>
    </ul>
    <p><strong>The claim you found:</strong></p>
    <div class="answer-space">
        <em>Tool/Model:</em><br><br>
        <em>Claim:</em><br><br>
        <em>Source URL:</em>
    </div>
</div>

<div class="step">
    <h3>Step 2: Investigate the Benchmark</h3>
    <div class="answer-space">
        <em>What is being measured? (accuracy, speed, user satisfaction?)</em><br><br>
        <em>How was it measured? (what test? what data? who ran it?)</em><br><br>
        <em>Who created the benchmark? (the company itself? independent researchers?)</em><br><br>
        <em>Is methodology documented? Can you find details?</em>
    </div>
</div>

<div class="step">
    <h3>Step 3: Red Flag Checklist</h3>
    <p>Check for common issues:</p>
    <div class="answer-space">
        <em>☐ Cherry-picked metrics (only showing where they win)?</em><br><br>
        <em>☐ Self-reported results (company tested their own product)?</em><br><br>
        <em>☐ Outdated comparisons (comparing to old versions of competitors)?</em><br><br>
        <em>☐ Unclear methodology (can't tell how test was conducted)?</em><br><br>
        <em>☐ Narrow test conditions (works in lab but not real world)?</em><br><br>
        <em>☐ Missing context (what's the baseline? what's human performance?)</em>
    </div>
</div>

<div class="step">
    <h3>Step 4: Your Assessment</h3>
    <div class="answer-space">
        <em>What issues (if any) did you identify?</em><br><br>
        <em>How much should you trust this benchmark claim? Why?</em><br><br>
        <em>What additional information would you need to evaluate this fairly?</em>
    </div>
</div>

<div class="note">
    <p><strong>Key Insight:</strong> Benchmark claims are marketing as much as science. Companies choose which benchmarks to highlight and how to present results. A healthy skepticism—not cynicism, but critical evaluation—serves you well.</p>
</div>

<div class="submit">
    <h3>Submission</h3>
    <p>Submit your benchmark claim, investigation notes, red flag analysis, and overall assessment. Consider for Source Evaluation or Graphs & Visualization portfolio artifact.</p>
</div>

</body>
</html>
